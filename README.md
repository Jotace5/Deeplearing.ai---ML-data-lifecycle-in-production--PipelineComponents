## Deeplearing.ai course: ML-data-lifecycle-in-production 

### Assignment: Data Pipeline Components for Production ML

## Project Overview
This week's graded programming exercise culminates our learning journey by applying the first three steps crucial in a production machine learning project - Data Ingestion, Data Validation, and Data Transformation. Your task is to build a production-ready data pipeline, focusing on these key aspects.

## Objectives
This assignment is designed to showcase your proficiency in integrating various tools for analyzing, preparing, and transforming datasets. Your skills will be demonstrated through the following tasks:
- Performing feature selection.
- Ingesting the dataset.
- Generating dataset statistics.
- Creating a schema based on domain knowledge.
- Establishing schema environments.
- Visualizing dataset anomalies.
- Preprocessing, transforming, and engineering features.
- Tracking data pipeline provenance using ML Metadata.

## Table of Contents
1. **Imports**
2. **Load the Dataset**
3. **Feature Selection**
   - Exercise 1: Feature Selection
4. **Data Pipeline**
   - 4.1 Setup the Interactive Context
   - 4.2 Generating Examples
     - Exercise 2: ExampleGen
   - 4.3 Computing Statistics
     - Exercise 3: StatisticsGen
   - 4.4 Inferring the Schema
     - Exercise 4: SchemaGen
   - 4.5 Curating the Schema
     - Exercise 5: Curating the Schema
   - 4.6 Schema Environments
     - Exercise 6: Define the serving environment
   - 4.7 Generate new statistics using the updated schema
     - Exercise 7: ImportSchemaGen
     - Exercise 8: StatisticsGen with the new schema
   - 4.8 Check anomalies
     - Exercise 9: ExampleValidator
   - 4.9 Feature Engineering
     - Exercise 10: preprocessing function
     - Exercise 11: Transform
5. **ML Metadata**
   - 5.1 Accessing stored artifacts
   - 5.2 Tracking artifacts
     - Exercise 12: Get parent artifacts

## How to Use
Follow the exercises in sequential order, beginning from importing necessary libraries to the final steps of tracking artifacts. Each section is designed to build upon the previous one, ensuring a comprehensive understanding of each component in the data pipeline.

## Contributing
Contributions to improve the project are welcomed. Feel free to suggest enhancements, submit pull requests, or open issues for discussion.

